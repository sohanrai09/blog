[{"id":0,"href":"/blog/posts/mdt_iosxr/","title":"Model Driven Telemetry on IOS-XR","section":"Posts","content":"I know I\u0026rsquo;m very late to the party probably everybody has already moved on to Telemetry. But during the Annual Shutdown of Dec \u0026lsquo;24, I had some spare time, so I wanted to set this up in my personal lab and play around. At work, I have been testing Model Driven Telemetry(MDT) on Cisco\u0026rsquo;s IOS-XR for a while now, so I wanted to share some of my learnings through this post. I will be primarily focusing on Cisco IOS-XR\u0026rsquo;s implementation of MDT, more precisely GRPC DIAL-OUT in this post.\nI\u0026rsquo;m using Cisco IOS-XRv 9000 running 7.9.1 for this exercise.\nThere are already tons of content on setting up the TIG(Telegraf, InfluxDB, Grafana) stack, I just want to mention here the Telegraf configuration for a quick reference.\n# telegraf.conf # Global Agent Configuration [agent] hostname = \u0026#34;telemetry-container\u0026#34; flush_interval = \u0026#34;15s\u0026#34; interval = \u0026#34;15s\u0026#34; # gRPC Dial-Out Telemetry Listener [[inputs.cisco_telemetry_mdt]] transport = \u0026#34;grpc\u0026#34; service_address = \u0026#34;:57000\u0026#34; # Output Plugin InfluxDB [[outputs.influxdb_v2]] bucket = \u0026#34;mdtlab\u0026#34; urls = [\u0026#34;http://127.0.0.1:8086\u0026#34;] token = \u0026#34;enter the token here\u0026#34; organization = \u0026#34;lab\u0026#34; Configuration on IOS-XR # As mentioned earlier, I wil be using grpc dial-out option, and the required configuration on Cisco IOS-XR for this:\n! grpc no-tls ! telemetry model-driven destination-group DGroup2 address-family ipv4 192.168.100.1 port 57000 encoding self-describing-gpb protocol grpc no-tls ! ! sensor-group ISIS sensor-path Cisco-IOS-XR-clns-isis-oper:isis/instances/instance/summary sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper:rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/isis/as/information ! sensor-group MPLSTE sensor-path Cisco-IOS-XR-mpls-te-oper:mpls-te/tunnels/summary ! sensor-group SGroup2 sensor-path Cisco-IOS-XR-wdsysmon-fd-oper:system-monitoring/cpu-utilization sensor-path Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary ! sensor-group ipv4_bgp sensor-path Cisco-IOS-XR-ipv4-bgp-oper:bgp/instances/instance/instance-active/vrfs/vrf/process-info/global sensor-path Cisco-IOS-XR-ipv4-bgp-oper:bgp/instances/instance/instance-active/default-vrf/process-info/global sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper:rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/protocol/bgp/as ! sensor-group rib-ipv4 sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper:rib/rib-table-ids/rib-table-id/information sensor-path Cisco-IOS-XR-ip-rib-ipv4-oper:rib/vrfs/vrf/afs/af/safs/saf/ip-rib-route-table-names/ip-rib-route-table-name/routes/route ! sensor-group INT_STATS sensor-path Cisco-IOS-XR-infra-statsd-oper:infra-statistics/interfaces/interface/cache/data-rate/input-data-rate sensor-path Cisco-IOS-XR-infra-statsd-oper:infra-statistics/interfaces/interface/cache/data-rate/output-data-rate ! subscription ISIS sensor-group-id ISIS sample-interval 30000 destination-id DGroup2 ! subscription ISIS sensor-group-id ISIS sample-interval 30000 destination-id DGroup2 ! subscription Sub2 sensor-group-id SGroup2 sample-interval 30000 destination-id DGroup2 ! subscription MPLSTE sensor-group-id MPLSTE sample-interval 60000 destination-id DGroup2 ! subscription ipv4_bgp sensor-group-id ipv4_bgp sample-interval 30000 destination-id DGroup2 ! subscription rib-ipv4 sensor-group-id rib-ipv4 sample-interval 30000 destination-id DGroup2 ! subscription INT_STATS sensor-group-id INT_STATS sample-interval 30000 destination-id DGroup2 ! ! I have setup a bunch of things around system parameters, control plane and data plane. Please refer to Cisco Feature Navigator to get the YANG models as per your requirement.\nChecks on IOS-XR # RP/0/RP0/CPU0:PE1#show telemetry model-driven summary Tue Dec 31 07:23:58.009 UTC Subscriptions Total: 6 Active: 6 Paused: 0 Destination Groups Total: 1 Destinations grpc-tls: 0 grpc-nontls: 1 tcp: 0 udp: 0 dialin: 0 Active: 1 Sessions: 6 Connecting: 0 Sensor Groups Total: 6 Num of Unique Sensor Paths : 12 Sensor Paths Total: 12 Active: 12 Not Resolved: 0 Max Sensor Paths : 1000 Max Containers per path : 16 Minimum target defined cadence : 30000 Target Defined cadence factor : 2 RP/0/RP0/CPU0:PE1# Looking at one particular subscription\nRP/0/RP0/CPU0:PE1#show telemetry model-driven subscription Sub2 internal Tue Dec 31 07:26:47.149 UTC Subscription: Sub2 ------------- State: ACTIVE Sensor groups: Id: SGroup2 Sample Interval: 30000 ms Heartbeat Interval: NA Sensor Path: Cisco-IOS-XR-wdsysmon-fd-oper:system-monitoring/cpu-utilization Sensor Path State: Resolved Sensor Path: Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary Sensor Path State: Resolved Destination Groups: Group Id: DGroup2 Destination IP: 192.168.100.1 Destination Port: 57000 Encoding: self-describing-gpb Transport: grpc State: Active TLS : False Total bytes sent: 4140731 Total packets sent: 73 Last Sent time: 2024-12-31 07:26:47.3658113843 +0000 Collection Groups: ------------------ Id: 4 Sample Interval: 30000 ms Heartbeat Interval: NA Heartbeat always: False Encoding: self-describing-gpb Num of collection: 5 Incremental updates: 0 Collection time: Min: 201 ms Max: 328 ms Total time: Min: 205 ms Avg: 267 ms Max: 372 ms Total Deferred: 0 Total Send Errors: 0 Total Send Drops: 0 Total Other Errors: 0 No data Instances: 0 Last Collection Start:2024-12-31 07:26:47.3657951022 +0000 Last Collection End: 2024-12-31 07:26:17.3628194656 +0000 Sensor Path: Cisco-IOS-XR-wdsysmon-fd-oper:system-monitoring/cpu-utilization Sysdb Path: /oper/wdsysmon_fd/gl/* Count: 5 Method: DATALIST Min: 201 ms Avg: 237 ms Max: 328 ms Item Count: 11 Status: Active Missed Collections:0 send bytes: 3376266 packets: 15 dropped bytes: 0 Missed Heartbeats: 0 Filtered Item Count: 0 success errors deferred/drops Gets 0 0 List 0 0 Datalist 6 0 Finddata 0 0 GetBulk 0 0 Encode 0 0 Send 0 0 Id: 5 Sample Interval: 30000 ms Heartbeat Interval: NA Heartbeat always: False Encoding: self-describing-gpb Num of collection: 5 Incremental updates: 0 Collection time: Min: 10 ms Max: 45 ms Total time: Min: 13 ms Avg: 25 ms Max: 48 ms Total Deferred: 0 Total Send Errors: 0 Total Send Drops: 0 Total Other Errors: 0 No data Instances: 0 Last Collection Start:2024-12-31 07:26:17.3628195821 +0000 Last Collection End: 2024-12-31 07:26:17.3628216972 +0000 Sensor Path: Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary Sysdb Path: /oper/showd/node/*/show_mem Count: 5 Method: GET Min: 10 ms Avg: 23 ms Max: 45 ms Item Count: 11 Status: Active Missed Collections:0 send bytes: 3310 packets: 5 dropped bytes: 0 Missed Heartbeats: 0 Filtered Item Count: 0 success errors deferred/drops Gets 11 0 List 6 0 Datalist 0 0 Finddata 6 0 GetBulk 0 0 Encode 0 0 Send 0 0 RP/0/RP0/CPU0:PE1# Querying the InfluxDB\nselect \u0026#34;free_physical_memory\u0026#34;,\u0026#34;node_name\u0026#34; from \u0026#34;Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary\u0026#34; Interactive Table View (press q to exit mode, shift+up/down to navigate tables): Name: Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary ┏━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓ ┃ index ┃ time ┃ free_physical_memory ┃ node_name ┃ ┣━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━━━━━━━━━━━━╋━━━━━━━━━━━━┫ ┃ 1┃2024-12-30T04:28:52.419Z ┃ 652320768.0000000000┃0/RP0/CPU0 ┃ ┃ 2┃2024-12-30T04:28:52.423Z ┃ 2699067392.0000000000┃0/0/CPU0 ┃ ┃ 3┃2024-12-30T04:29:22.373Z ┃ 651173888.0000000000┃0/RP0/CPU0 ┃ ┃ 4┃2024-12-30T04:29:22.377Z ┃ 2699079680.0000000000┃0/0/CPU0 ┃ ┃ 5┃2024-12-30T04:29:52.357Z ┃ 650625024.0000000000┃0/RP0/CPU0 ┃ ┃ 6┃2024-12-30T04:29:52.361Z ┃ 2699071488.0000000000┃0/0/CPU0 ┃ ┃ 7┃2024-12-30T04:30:22.341Z ┃ 648966144.0000000000┃0/RP0/CPU0 ┃ ┃ 8┃2024-12-30T04:30:22.346Z ┃ 2696978432.0000000000┃0/0/CPU0 ┃ ┃ 9┃2024-12-30T04:30:52.431Z ┃ 647417856.0000000000┃0/RP0/CPU0 ┃ ┃ 10┃2024-12-30T04:30:52.441Z ┃ 2694713344.0000000000┃0/0/CPU0 ┃ ┃ 11┃2024-12-30T04:31:22.355Z ┃ 647303168.0000000000┃0/RP0/CPU0 ┃ ┃ 12┃2024-12-30T04:31:22.371Z ┃ 2694729728.0000000000┃0/0/CPU0 ┃ ┃ 13┃2024-12-30T04:31:52.344Z ┃ 647397376.0000000000┃0/RP0/CPU0 ┃ ┃ 14┃2024-12-30T04:31:52.347Z ┃ 2694721536.0000000000┃0/0/CPU0 ┃ ┃ 15┃2024-12-30T04:32:22.334Z ┃ 647389184.0000000000┃0/RP0/CPU0 ┃ ┃ 16┃2024-12-30T04:32:22.339Z ┃ 2694733824.0000000000┃0/0/CPU0 ┃ ┃ 17┃2024-12-30T04:32:52.356Z ┃ 645771264.0000000000┃0/RP0/CPU0 ┃ ┃ 18┃2024-12-30T04:32:52.361Z ┃ 2694598656.0000000000┃0/0/CPU0 ┃ ┃ 19┃2024-12-30T04:33:22.357Z ┃ 645820416.0000000000┃0/RP0/CPU0 ┃ ┃ 20┃2024-12-30T04:33:22.361Z ┃ 2694590464.0000000000┃0/0/CPU0 ┃ ┃ 21┃2024-12-30T04:33:52.39Z ┃ 645697536.0000000000┃0/RP0/CPU0 ┃ ┃ 22┃2024-12-30T04:33:52.394Z ┃ 2694574080.0000000000┃0/0/CPU0 ┃ ┃ 23┃2024-12-30T04:34:22.392Z ┃ 645849088.0000000000┃0/RP0/CPU0 ┃ ┃ 24┃2024-12-30T04:34:22.396Z ┃ 2702364672.0000000000┃0/0/CPU0 ┃ ┃ 25┃2024-12-30T04:34:52.364Z ┃ 645808128.0000000000┃0/RP0/CPU0 ┃ ┃ 26┃2024-12-30T04:34:52.369Z ┃ 2693156864.0000000000┃0/0/CPU0 ┃ ┣━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━━━━━━━━━━━━┻━━━━━━━━━━━━┫ ┃ 4 Columns, 5942 Rows, Page 1/229┃ ┃ Table 1/1, Statement 1/1┃ ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ Equivalent query for Grafana in Flex Language Syntax\nfrom(bucket: \u0026#34;mdtlab\u0026#34;) |\u0026gt; range(start: v.timeRangeStart, stop: v.timeRangeStop) |\u0026gt; filter(fn: (r) =\u0026gt; r[\u0026#34;_measurement\u0026#34;] == \u0026#34;Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary\u0026#34;) |\u0026gt; filter(fn: (r) =\u0026gt; r[\u0026#34;_field\u0026#34;] == \u0026#34;free_physical_memory\u0026#34;) |\u0026gt; aggregateWindow(every: v.windowPeriod, fn: mean, createEmpty: false) |\u0026gt; yield(name: \u0026#34;mean\u0026#34;) Personally, I found the Flex Language syntax a bit tricky to write from scratch, thankfully, we can use Query Builder option in InfluxDB GUI to get the appropriate Flex Language query for your needs.\nFinally, it all comes together in Grafana dashboard. Troubleshooting # It\u0026rsquo;s all well and good when things work fine but when they don\u0026rsquo;t, we need to know what logs/traces to check to narrow down the issue.\nI have simulated a failure scenario, due to which none of the sessions are Active, all are stuck in Connecting state.\nRP/0/RP0/CPU0:PE1#show telemetry model-driven subscription Sub2 internal Tue Dec 31 07:56:34.848 UTC Subscription: Sub2RP/0/RP0/CPU0:PE1#show telemetry model-driven summary Tue Dec 31 07:56:00.701 UTC Subscriptions Total: 6 Active: 0 Paused: 0 Destination Groups Total: 1 Destinations grpc-tls: 0 grpc-nontls: 1 tcp: 0 udp: 0 dialin: 0 Active: 0 Sessions: 0 Connecting: 6 Sensor Groups Total: 6 Num of Unique Sensor Paths : 12 Sensor Paths Total: 12 Active: 0 Not Resolved: 0 Max Sensor Paths : 1000 Max Containers per path : 16 Minimum target defined cadence : 30000 Target Defined cadence factor : 2 Checking one particular Subscription, there are no active collection groups.\nRP/0/RP0/CPU0:PE1# ------------- State: NA Sensor groups: Id: SGroup2 Sample Interval: 30000 ms Heartbeat Interval: NA Sensor Path: Cisco-IOS-XR-wdsysmon-fd-oper:system-monitoring/cpu-utilization Sensor Path State: Resolved Sensor Path: Cisco-IOS-XR-nto-misc-oper:memory-summary/nodes/node/summary Sensor Path State: Resolved Destination Groups: Group Id: DGroup2 Destination IP: 192.168.100.1 Destination Port: 57000 Encoding: self-describing-gpb Transport: grpc State: NA TLS : False Collection Groups: ------------------ No active collection groups RP/0/RP0/CPU0:PE1# Checking the telemetry model-driven traces, we can see that TCP Connection is failing to Establish.\nRP/0/RP0/CPU0:PE1#show telemetry model-driven trace all reverse Tue Dec 31 07:59:49.160 UTC 24118 wrapping entries (26496 possible, 24704 allocated, 0 filtered, 351346 total) Dec 31 07:59:44.446 m2m/mdt/go-info 0/RP0/CPU0 t31604 5469 [mdt_go_trace_info]: mdtDialer:279 1: Reuse dialerChan 0xc000010218 for default Dec 31 07:59:44.446 m2m/mdt/go-info 0/RP0/CPU0 t31604 5468 [mdt_go_trace_info]: getAddDialerChanWithLock:153 1:Found existing dialer for namespace default Dec 31 07:59:44.446 m2m/mdt/go-info 0/RP0/CPU0 t31604 5467 [mdt_go_trace_info]: mdtDialer:269 1: namespace default, args 192.168.100.1:57000 Dec 31 07:59:44.445 m2m/mdt/go-info 0/RP0/CPU0 t31604 5466 [mdt_go_trace_info]: mdtConnEstablish:268 dial: target 192.168.100.1:57000 Dec 31 07:59:44.445 m2m/mdt/go-info 0/RP0/CPU0 t31604 5465 [mdt_go_trace_info]: mdtConnEstablish:229 1: req 503, TLS is false, cert , host , compression . Dec 31 07:59:44.445 m2m/mdt/go-info 0/RP0/CPU0 t31604 5464 [mdt_go_trace_info]: mdtConnEstablish:229 1: Dialing out to 192.168.100.1:57000, req 503 Dec 31 07:59:44.445 m2m/mdt/go-info 0/RP0/CPU0 t31604 5463 [mdt_go_trace_info]: dialReqAgent:489 1: req 501, entries when dequeue is 3 Dec 31 07:59:44.445 m2m/mdt/subdb 0/RP0/CPU0 t31604 5462 [mdt_conn_grpc_establish_done]: Failed to establish conn 0 Dec 31 07:59:44.445 m2m/mdt/subdb 0/RP0/CPU0 t31604 5461 [mdt_conn_grpc_establish_done]: Got grpc establish callback 501, chan 18446744073709551615, status 1 Dec 31 07:59:44.445 m2m/mdt/go-info 0/RP0/CPU0 t31604 5460 [mdt_go_trace_error]: mdtConnEstablish:295 1: grpc service call failed, ReqId 501, 192.168.100.1:57000, rpc error: code = Unavailable desc = connection error: desc = \u0026#34;transport: error while dialing: dial tcp 192.168.100.1:57000: i/o timeout\u0026#34; grpc traces also reveal the same.\nRP/0/RP0/CPU0:PE1#show grpc trace all reverse | i 07:59:44 Tue Dec 31 08:37:28.700 UTC Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] Channel Connectivity change to CONNECTING Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] pickfirstBalancer: UpdateSubConnState: 0xc00001e8e0, {CONNECTING \u0026lt;nil\u0026gt;} Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Subchannel picks a new address \u0026#34;192.168.100.1:57000\u0026#34; to connect Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Subchannel Connectivity change to CONNECTING Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] blockingPicker: the picked transport is not ready, loop back to repick Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Channel switches to new LB policy \u0026#34;pick_first\u0026#34; Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] ClientConn switching balancer to \u0026#34;pick_first\u0026#34; Dec 31 07:59:44.446 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] ccResolverWrapper: sending update to cc: {[{192.168.100.1:57000 \u0026lt;nil\u0026gt; 0 \u0026lt;nil\u0026gt;}] \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;} Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] scheme \u0026#34;\u0026#34; not registered, fallback to default scheme Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] parsed scheme: \u0026#34;\u0026#34; Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Subchannel Connectivity change to SHUTDOWN Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Channel Connectivity change to SHUTDOWN Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Channel Connectivity change to TRANSIENT_FAILURE Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] pickfirstBalancer: UpdateSubConnState: 0xc000019fb0, {TRANSIENT_FAILURE connection error: desc = \u0026#34;transport: error wh ile dialing: dial tcp 192.168.100.1:57000: i/o timeout\u0026#34;} Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] Subchannel Connectivity change to TRANSIENT_FAILURE Dec 31 07:59:44.445 ems/grpc 0/RP0/CPU0 t31604 EMS-GRPC: [core] grpc: addrConn.createTransport failed to connect to {192.168.100.1:57000 192.168.100.1:57000 \u0026lt;nil\u0026gt; 0 \u0026lt;nil\u0026gt;}. Err: con nection error: desc = \u0026#34;transport: error while dialing: dial tcp 192.168.100.1:57000: i/o timeout\u0026#34; RP/0/RP0/CPU0:PE1# We can also check the TCP connection state on the node. Here the TCP connection is not moving past SYN_SENT, as it has not received SYN+ACK from the Server, eventually it times out.\nRP/0/RP0/CPU0:PE1#bash netstat -an Tue Dec 31 07:59:44.895 UTC Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 1 211.0.0.9:61390 192.168.100.1:57000 SYN_SENT tcp6 0 0 :::57400 :::* LISTEN Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 14646215 /var/lib/malloc_stat/9580 unix 2 [ ] DGRAM 14646222 RP/0/RP0/CPU0:PE1# In this particular case, Server doesn\u0026rsquo;t have a route to Router\u0026rsquo;s Loopback 211.0.0.9, due to which it is unable to respond to Router\u0026rsquo;s TCP SYN, as soon I added the route, Connections started coming up.\nRP/0/RP0/CPU0:PE1#show grpc trace all reverse Tue Dec 31 08:50:05.358 UTC 83163 wrapping entries (549888 possible, 328448 allocated, 0 filtered, 149016 total) Dec 31 08:48:04.729 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] Channel Connectivity change to READY Dec 31 08:48:04.729 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] pickfirstBalancer: UpdateSubConnState: 0xc0001646c0, {READY \u0026lt;nil\u0026gt;} Dec 31 08:48:04.729 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] Subchannel Connectivity change to READY Dec 31 08:48:04.709 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] Channel Connectivity change to CONNECTING Dec 31 08:48:04.709 ems/grpc 0/RP0/CPU0 t31542 EMS-GRPC: [core] pickfirstBalancer: UpdateSubConnState: 0xc0001646c0, {CONNECTING \u0026lt;nil\u0026gt;} Dec 31 08:48:04.708 ems/grpc 0/RP0/CPU0 t31659 EMS-GRPC: [core] Subchannel picks a new address \u0026#34;192.168.100.1:57000\u0026#34; to connect Dec 31 08:48:04.708 ems/grpc 0/RP0/CPU0 t31659 EMS-GRPC: [core] Subchannel Connectivity change to CONNECTING Dec 31 08:48:04.708 ems/grpc 0/RP0/CPU0 t31659 EMS-GRPC: [core] blockingPicker: the picked transport is not ready, loop back to repick Dec 31 08:48:04.708 ems/grpc 0/RP0/CPU0 t31659 EMS-GRPC: [core] Channel switches to new LB policy \u0026#34;pick_first\u0026#34; Dec 31 08:48:04.708 ems/grpc 0/RP0/CPU0 t31659 EMS-GRPC: [core] ClientConn switching balancer to \u0026#34;pick_first\u0026#34; Dec 31 08:48:04.708 ems/grpc 0/RP0/CPU0 t31659 EMS-GRPC: [core] ccResolverWrapper: sending update to cc: {[{192.168.100.1:57000 \u0026lt;nil\u0026gt; 0 \u0026lt;nil\u0026gt;}] \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;} RP/0/RP0/CPU0:PE1#bash netstat -an Tue Dec 31 08:51:09.756 UTC Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 211.0.0.9:60665 192.168.100.1:57000 ESTABLISHED tcp 0 0 211.0.0.9:60658 192.168.100.1:57000 ESTABLISHED tcp 0 0 211.0.0.9:60659 192.168.100.1:57000 ESTABLISHED tcp 0 0 211.0.0.9:60668 192.168.100.1:57000 ESTABLISHED tcp 0 0 211.0.0.9:60661 192.168.100.1:57000 ESTABLISHED tcp 0 0 211.0.0.9:60660 192.168.100.1:57000 ESTABLISHED tcp6 0 0 :::57400 :::* LISTEN Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 13474827 /var/lib/malloc_stat/2458 unix 2 [ ] DGRAM 13474834 RP/0/RP0/CPU0:PE1# Validating YANG Data model using built-in Python script # IOS-XR comes with a handy built-in python script, mdt_exec.py which can be invoked to quickly check the YANG model for any particular path.\nRP/0/RP0/CPU0:PE1#run mdt_exec.py -s Cisco-IOS-XR-clns-isis-oper:isis/instance$ Tue Dec 31 08:56:16.248 UTC { \u0026#34;encoding_path\u0026#34;: \u0026#34;Cisco-IOS-XR-clns-isis-oper:isis/instances/instance/summary\u0026#34;, \u0026#34;subscription_id_str\u0026#34;: \u0026#34;app_TEST_200000001\u0026#34;, \u0026#34;collection_start_time\u0026#34;: \u0026#34;1735635376550\u0026#34;, \u0026#34;msg_timestamp\u0026#34;: \u0026#34;1735635376562\u0026#34;, \u0026#34;collection_end_time\u0026#34;: \u0026#34;1735635376562\u0026#34;, \u0026#34;node_id_str\u0026#34;: \u0026#34;PE1\u0026#34;, \u0026#34;data_json\u0026#34;: [ { \u0026#34;keys\u0026#34;: [ { \u0026#34;instance-name\u0026#34;: \u0026#34;1\u0026#34; } ], \u0026#34;timestamp\u0026#34;: \u0026#34;1735635376561\u0026#34;, \u0026#34;content\u0026#34;: { \u0026#34;l2-adjacencies\u0026#34;: 3, \u0026#34;l1-routers\u0026#34;: 0, \u0026#34;l1ls-ps\u0026#34;: 0, \u0026#34;l2ls-ps\u0026#34;: 5, \u0026#34;l2-routers\u0026#34;: 5, \u0026#34;running-levels\u0026#34;: \u0026#34;isis-levels-2\u0026#34;, \u0026#34;l1-adjacencies\u0026#34;: 0, \u0026#34;l1l2-adjacencies\u0026#34;: 0 } } ], \u0026#34;collection_id\u0026#34;: \u0026#34;185\u0026#34; }, ^CDone This can also help in verifying if the sensor-path you\u0026rsquo;re trying is valid or not. Using an invalid path will show up as Not Resolved while checking the sensor-path state.\nRP/0/RP0/CPU0:PE1#show telemetry model-driven subscription INVALID_SUB Fri Jan 3 04:09:42.372 UTC Subscription: INVALID_SUB ------------- State: NA Sensor groups: Id: INVALID_PATH Sample Interval: 90000 ms Heartbeat Interval: NA Sensor Path: Cisco-IOS-XR-dnx-driver-fabric-plane-oper:fabric/plane-table/plane Sensor Path State: Not Resolved Destination Groups: Group Id: DGroup2 Destination IP: 192.168.100.1 Destination Port: 57000 Encoding: self-describing-gpb Transport: grpc State: NA TLS : False Collection Groups: ------------------ No active collection groups RP/0/RP0/CPU0:PE1# RP/0/RP0/CPU0:PE1#run mdt_exec.py -s Cisco-IOS-XR-dnx-driver-fabric-plane-oper$ Fri Jan 3 04:10:06.983 UTC {\"Sub_id\" : \"200000001\", \"error\" : \"Module 'Cisco-IOS-XR-dnx-driver-fabric-plane-oper' not recognized or supported for the specified operation\"} {\"Sub_id\" : \"200000001\", \"error\" : \"Module 'Cisco-IOS-XR-dnx-driver-fabric-plane-oper' not recognized or supported for the specified operation\"} ^CDone RP/0/RP0/CPU0:PE1# This was just scratching the surface when it comes to possibilities with Telemetry but it was great fun setting everything up and to finally see those shinny graphs. Cisco has some very good documentation on this subject matter, please check them out if you\u0026rsquo;re thinking of setting this up at home or at work.\nReference # https://xrdocs.io/telemetry/\nhttps://xrdocs.io/telemetry/tutorials/\n"},{"id":1,"href":"/blog/posts/network-tui/","title":"Network TUI","section":"Posts","content":"At the end of my previous blog post I mentioned about wanting to work on Textual, and I\u0026rsquo;m excited to share here my first project using Textual. I feel like for us network engineers, working on a CLI makes our work more enjoyable so naturally, building a TUI(Terminal User Interface) to do some of the automation tasks was a no-brainer to me. I have called it Net-TUI, a TUI application to do few network automation tasks.\nNet-TUI # As mentioned earlier, I\u0026rsquo;m using Textual to build the TUI App and to help me with networking tasks, I\u0026rsquo;m using Nornir. Net-TUI is broadly split into three sections. 1.Dashboard 2.Checker and 3.Generator. I will be going through each of these in the following sections.\nDashboard # To anyone following my blog, you would know that I went over building a Networking Dashboard in the previous blog post. I\u0026rsquo;m using it as a reference here with some enhancements and user interactions to make it more \u0026lsquo;App like\u0026rsquo;. Below is the snippet of how it looks like when the App is launched. As you can see, user has an option to provide the device name of which they want to build the Dashboard off. device name input comes with a nice little dropdown and autocomplete feature, which in this case is the list of available devices from the Nornir Inventory, which gets \u0026lsquo;autocompleted\u0026rsquo; as we type along.\nWithout going into more details of the data shown in Dashboard, as I have explained it my previous blog post, I would like to highlight few enhancements made to it. Unlike the previous version of Dashboard where the routing protocols were pre defined, in this version, there is an intelligence built to identify the protocols currently configured on the device and then build the Dashboard around that. As of now this is limited to some of the well-known protocols like BGP, ISIS, OSPF, MPLS, LDP but this can be easily extended to include anything else. Below snippet shows the end result of Dashboard.\nChecker # This section has three sub-categories, each with an interesting function associated with them.\nCard Look-up # As the name suggests, this function can be used to look-up any particular card/FPC across the inventory of hosts as defined in Nornir. Input for card name again comes with a dropdown and autocomplete feature. Any matches to the card will be displayed along with the device name and FPC Slot information. If no matches are found, same will be displayed to the user. I found this feature to be quite handy as I have to deal with a huge inventory of devices at work and this gives a quick and easy way of knowing the cards deployed currently in the network. List of cards which is used to provide the dropdown options currently comes from a static file but a future enhancement could be to retrieve that information dynamically from Juniper/vendor websites.\nConfig search # This function can be used to quickly scan through the configuration of all the devices for any particular pattern match. Let\u0026rsquo;s assume we want to check if a particular user is configured on all the devices or if we have RE(Routing Engine) Filter configured on all devices, this can help with these tasks and many more. Any matches found in the configuration will be displayed along with the device name.\nFetching Command output # This function helps in retrieving the output of any given CLI command from all the devices. Again, the available commands are displayed as dropdown with autocompletefeature. List of commands comes from a static file, so one can add any commands they would like to offer the user as an option to execute. Output of the commands will be displayed along with the device name.\nGenerator # My inspiration to this section comes from my days at Network Ops where every other day I used to work on some maintenance activities and with this comes the crucial part of pre and post network validation. Since each device we work on can be different, we could not always have the same checks for validation. Generator solves this problem by generating a list of commands as per the protocols configured on the device. User also has an option to select if they would want terse or verbose level of commands and the commands are generated accordingly, with terse being the default. Commands for each protocols are pre defined in a YAML file and one can make any changes to it as per their business needs. Once the commands are generated, user can either copy it to a clipboard using Copy to clipboard button at the Footer of the App or by simply pressing c in the keyboard. A pop-up notification is generated to confirm that commands are copied to the clipboard. But better yet, if the user wishes to run the commands and fetch the output from the device, they can use Fetch output or pressing f. The App would then connect to the device and execute the commands and store the output in a .txt file, which will be displayed to the user at the end.\nI honestly think that this blog post, with the screenshots, doesn\u0026rsquo;t do justice to the TUI App. Please check out the screen recording here to truly appreciate the beauty of Textual. This probably is the simplest version of TUIs out there but hopefully it goes to show what\u0026rsquo;s possible with Textual. Folks at Textual are adding new and interesting features regularly which gives us users more options to play with to customize our TUI Apps. This project has been the most fun filled projects I have worked on and hopefully I\u0026rsquo;ve been able to capture and present that here. Please feel free to reach out to me in case you need any further clarifications, code repository can be found here. Checkout another great Network TUI built by Danny Wade called net-textorial and give him a follow as he is doing amazing things in the Network Automation field.\nThank you!\n"},{"id":2,"href":"/blog/posts/network-dashboard/","title":"Network Dashboard","section":"Posts","content":"In this blog post I will be going through how I went about building a Network Dashboard using couple of my favorite Python libraries, Nornir and Rich. I\u0026rsquo;m quite sure that if you have been exploring the network automation world, you would have come across Nornir already. And similarly there is a very good chance that you have also come across Rich, which is in my opinion one of the coolest libraries out there! If you are someone who loves working in CLI, like I do, you will absolutely love Rich!\nNornir is a pure python framework which makes use of Plugins to accomplish various tasks. As we go through this post you will see how these Plugins are super useful in getting things done and if you prefer to use a different plugin you can do so with minimal change. Like for instance, I will be using the Juniper PyEZ plugin to interact and fetch details from the routers, you can instead use Napalm, Netmiko, etc as per your convenience. The Inventory is the critical part of Nornir and it is mainly comprised of hosts, groups and config files in yaml format. For my script, I will be using a very basic version of Inventory, you can get really creative to make it very robust as per your needs.\n(venv) sohanr@sohanr-mbp dashboard % tree . ├── config.yaml ├── dashboard.py ├── groups.yaml ├── hosts.yaml ├── nornir.log └── test.py 1 directory, 6 files hosts.yaml # In hosts.yaml file we define details of hosts we will be working with in our script.\n--- vMX1: hostname: vmx1.norn.lab port: 31003 groups: - nos vMX2: hostname: vmx2.norn.lab port: 31006 groups: - nos vMX3: hostname: vmx3.norn.lab port: 31009 groups: - nos groups.yaml # In groups.yaml file we define any group specific attributes, this can include any login information, platform information, etc\n--- devices: username: username1 password: Password1 nos: platform: junos groups: - devices config.yaml # Everything comes together in a config.yaml file, where you can define pointers to your hosts and group files.\n--- inventory: options: host_file: \u0026#34;hosts.yaml\u0026#34; group_file: \u0026#34;groups.yaml\u0026#34; runner: options: num_workers: 10 End Goal # Before we dive into the script, let\u0026rsquo;s look at the end result so that we can then break things down to sections to tackle it one by one.\nThere are two main sections to the script, one is retrieving the necessary data from the routers and two, building the dashboard itself. As mentioned in the beginning of this post, I will be using Junos PyEZ to fetch the network data. PyEZ offers RPCs to fetch network information in structured format which then makes it easy for us to navigate through the data to get the required information. Let\u0026rsquo;s take a look at one example where we try to fetch the BGP information from the network.\nPyEZ RPC in Nornir # In this example, we will be using a task named pyez_rpc in the PyEZ plugin for RPC. For more information on the plugin, please refer to the documentation here.\n(venv) sohanr@sohanr-mbp dashboard % python Python 3.9.6 (default, Sep 26 2022, 11:37:49) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; from nornir import InitNornir \u0026gt;\u0026gt;\u0026gt; from nornir_pyez.plugins.tasks import pyez_rpc \u0026gt;\u0026gt;\u0026gt; nr = InitNornir() \u0026gt;\u0026gt;\u0026gt; output = nr.run(task=pyez_rpc, func=\u0026#39;get-bgp-summary-information\u0026#39;) \u0026gt;\u0026gt;\u0026gt; output AggregatedResult (pyez_rpc): {\u0026#39;vMX1\u0026#39;: MultiResult: [Result: \u0026#34;pyez_rpc\u0026#34;], \u0026#39;vMX2\u0026#39;: MultiResult: [Result: \u0026#34;pyez_rpc\u0026#34;], \u0026#39;vMX3\u0026#39;: MultiResult: [Result: \u0026#34;pyez_rpc\u0026#34;]} \u0026gt;\u0026gt;\u0026gt; Nornir returns the result as an Aggregated Result object, which is a dict-like object we can iterate over to get the required information. Let\u0026rsquo;s say I want to look into one of the host\u0026rsquo;s data, I can do that as shown below.\n\u0026gt;\u0026gt;\u0026gt; output AggregatedResult (pyez_rpc): {\u0026#39;vMX1\u0026#39;: MultiResult: [Result: \u0026#34;pyez_rpc\u0026#34;], \u0026#39;vMX2\u0026#39;: MultiResult: [Result: \u0026#34;pyez_rpc\u0026#34;], \u0026#39;vMX3\u0026#39;: MultiResult: [Result: \u0026#34;pyez_rpc\u0026#34;]} \u0026gt;\u0026gt;\u0026gt; bgp_data = output[\u0026#39;vMX1\u0026#39;][0].result \u0026gt;\u0026gt;\u0026gt; bgp_data {\u0026#39;bgp-information\u0026#39;: {\u0026#39;bgp-thread-mode\u0026#39;: \u0026#39;BGP I/O\u0026#39;, \u0026#39;thread-state\u0026#39;: None, \u0026#39;default-ebgp-advertise-mode\u0026#39;: \u0026#39;accept\u0026#39;, \u0026#39;default-ebgp-receive-mode\u0026#39;: \u0026#39;accept\u0026#39;, \u0026#39;group-count\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;peer-count\u0026#39;: \u0026#39;2\u0026#39;, \u0026#39;down-peer-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;bgp-rib\u0026#39;: {\u0026#39;@style\u0026#39;: \u0026#39;brief\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;inet.0\u0026#39;, \u0026#39;total-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;received-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;accepted-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;active-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;suppressed-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;history-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;damped-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;total-external-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;active-external-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;accepted-external-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;suppressed-external-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;total-internal-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;active-internal-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;accepted-internal-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;suppressed-internal-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;pending-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;bgp-rib-state\u0026#39;: \u0026#39;BGP restart is complete\u0026#39;}, \u0026#39;bgp-peer\u0026#39;: [{\u0026#39;@style\u0026#39;: \u0026#39;terse\u0026#39;, \u0026#39;@heading\u0026#39;: \u0026#39;Peer AS InPkt OutPkt OutQ Flaps Last Up/Dwn State|#Active/Received/Accepted/Damped...\u0026#39;, \u0026#39;peer-address\u0026#39;: \u0026#39;10.100.100.2\u0026#39;, \u0026#39;peer-as\u0026#39;: \u0026#39;64522\u0026#39;, \u0026#39;input-messages\u0026#39;: \u0026#39;149\u0026#39;, \u0026#39;output-messages\u0026#39;: \u0026#39;149\u0026#39;, \u0026#39;route-queue-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;flap-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;elapsed-time\u0026#39;: {\u0026#39;@seconds\u0026#39;: \u0026#39;4024\u0026#39;, \u0026#39;#text\u0026#39;: \u0026#39;1:07:04\u0026#39;}, \u0026#39;peer-state\u0026#39;: {\u0026#39;@format\u0026#39;: \u0026#39;Establ\u0026#39;, \u0026#39;#text\u0026#39;: \u0026#39;Established\u0026#39;}, \u0026#39;bgp-rib\u0026#39;: {\u0026#39;@style\u0026#39;: \u0026#39;terse\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;inet.0\u0026#39;, \u0026#39;active-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;received-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;accepted-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;suppressed-prefix-count\u0026#39;: \u0026#39;0\u0026#39;}}, {\u0026#39;@style\u0026#39;: \u0026#39;terse\u0026#39;, \u0026#39;peer-address\u0026#39;: \u0026#39;10.100.100.3\u0026#39;, \u0026#39;peer-as\u0026#39;: \u0026#39;64522\u0026#39;, \u0026#39;input-messages\u0026#39;: \u0026#39;150\u0026#39;, \u0026#39;output-messages\u0026#39;: \u0026#39;150\u0026#39;, \u0026#39;route-queue-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;flap-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;elapsed-time\u0026#39;: {\u0026#39;@seconds\u0026#39;: \u0026#39;4024\u0026#39;, \u0026#39;#text\u0026#39;: \u0026#39;1:07:04\u0026#39;}, \u0026#39;peer-state\u0026#39;: {\u0026#39;@format\u0026#39;: \u0026#39;Establ\u0026#39;, \u0026#39;#text\u0026#39;: \u0026#39;Established\u0026#39;}, \u0026#39;bgp-rib\u0026#39;: {\u0026#39;@style\u0026#39;: \u0026#39;terse\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;inet.0\u0026#39;, \u0026#39;active-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;received-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;accepted-prefix-count\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;suppressed-prefix-count\u0026#39;: \u0026#39;0\u0026#39;}}]}} \u0026gt;\u0026gt;\u0026gt; As you can see, we see a structured data being returned from the device and now we can navigate through it like we do with any dict-like object in python to get the desired information.\n\u0026gt;\u0026gt;\u0026gt; total_peers = bgp_data[\u0026#39;bgp-information\u0026#39;][\u0026#39;peer-count\u0026#39;] \u0026gt;\u0026gt;\u0026gt; down_peers = bgp_data[\u0026#39;bgp-information\u0026#39;][\u0026#39;down-peer-count\u0026#39;] \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; total_peers \u0026#39;2\u0026#39; \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; down_peers \u0026#39;0\u0026#39; \u0026gt;\u0026gt;\u0026gt; Hopefully with this as a reference, you should be able to work your way through rest of the data retrieval code.\nBuilding Dashboard using Rich # The easiest part in the dashboard is the Progress Bars we see at the top.\nI\u0026rsquo;m using another Nornir Plugin to do this, called Nornir_Rich. It\u0026rsquo;s very simple and straight forward to use but the results are really amazing! It is quite literally the best of two worlds, Rich and Nornir!\nNext, I\u0026rsquo;m using Tables to display the information gathered from the device. Let\u0026rsquo;s take an example of System Information table. sys_info_table = Table(show_lines=True, show_header=False, box=box.ASCII, title=\u0026#39;System Information\u0026#39;) sys_info_table.add_column(\u0026#34;Field\u0026#34;, justify=\u0026#34;right\u0026#34;, style=\u0026#34;magenta\u0026#34;, width=18) sys_info_table.add_column(\u0026#34;Details\u0026#34;, style=\u0026#34;cyan\u0026#34;, width=50) sys_info_table.add_row(\u0026#39;SW version\u0026#39;, version) sys_info_table.add_row(\u0026#39;Model\u0026#39;, model) sys_info_table.add_row(\u0026#39;Serial Number\u0026#39;, serial_num) sys_info_table.add_row(\u0026#39;RE0 uptime\u0026#39;, re0_uptime) sys_info_table.add_row(\u0026#39;RE0 last reboot reason\u0026#39;, re0_last_reboot_reason) sys_info_table.add_row(\u0026#39;RE1 uptime\u0026#39;, re1_uptime) sys_info_table.add_row(\u0026#39;RE1 last reload reason\u0026#39;, re1_last_reboot_reason) Variables like version, model, etc are obtained by navigating through the AggregatedResult object, as explained earlier.\nIn the dashboard, Memory \u0026amp; CPU Information information is depicted in a rather interesting format. Underneath, it is still a Table but I\u0026rsquo;m using Emojis to represent the values, this is how the code looks like. mem_cpu_table = Table(show_header=False, box=box.ASCII, width=50, title=\u0026#39;Memory \u0026amp; CPU Information\u0026#39;) mem_cpu_table.add_column(\u0026#34;Field\u0026#34;, justify=\u0026#34;left\u0026#34;, style=\u0026#34;magenta\u0026#34;) if used_mem \u0026gt; 20: # To reduce the number of emojis/diamonds displayed mem_cpu_table.add_row(\u0026#34;:large_blue_diamond:\u0026#34; * (int(int(used_mem)/5)) + f\u0026#34; {used_mem}%\u0026#34; + \u0026#34;\\n\\n\u0026#34;, style=\u0026#39;cyan\u0026#39;) else: mem_cpu_table.add_row(\u0026#34;:large_blue_diamond:\u0026#34; * int(used_mem) + f\u0026#34; {used_mem}%\u0026#34; + \u0026#34;\\n\\n\u0026#34;, style=\u0026#39;cyan\u0026#39;) if int(cpu_usage) \u0026gt; 20: mem_cpu_table.add_row(\u0026#34;:large_orange_diamond:\u0026#34; * (int(int(cpu_usage)/2)) + f\u0026#34; {cpu_usage}%\u0026#34; + \u0026#34;\\n\\n\\n\u0026#34;, style=\u0026#39;magenta\u0026#39;) else: mem_cpu_table.add_row(\u0026#34;:large_orange_diamond:\u0026#34; * int(int(cpu_usage)) + f\u0026#34; {cpu_usage}%\u0026#34; + \u0026#34;\\n\\n\\n\u0026#34;, style=\u0026#39;magenta\u0026#39;) mem_cpu_table.add_row(\u0026#34;:large_blue_diamond: memory in-use\\t:large_orange_diamond: cpu in-use\u0026#34;) Once I have the 3 tables in place, I put them together in one single table. Note that Memory \u0026amp; CPU Information \u0026amp; Commit Information were merged together to form a single mem_cpu_commit_table table # Everything comes together, all the tables are put into one main table, which is then rendered in a Panel main_table = Table(show_lines=True, show_header=False) main_table.add_column(justify=\u0026#34;right\u0026#34;, style=\u0026#34;magenta\u0026#34;) main_table.add_column(justify=\u0026#34;right\u0026#34;, style=\u0026#34;green\u0026#34;) main_table.add_column(justify=\u0026#34;right\u0026#34;, style=\u0026#34;magenta\u0026#34;) main_table.add_row(sys_info_table, protocols_table, mem_cpu_commit_table) Next, we make use of Panels to place our final table. We repeat the same procedure for all the hosts in our inventory and keep appending the panels of each host into a list named panel_list.\npanel = Panel(main_table, width=200,title=router, box=box.DOUBLE) panel_list.append(panel) Finally, we iterate over the panel_list and print the panels into the console using console.print. I would also like to highlight another element in the dashboard that appears when the script is building the dashboard (unfortunately the snapshot of the dashboard doesn\u0026rsquo;t show it) i.e., Spinner. Spinners are nice when you want to display an animation when the script is executing a piece of code and awaiting completion.\nI know that I skimmed over a lot of details but hopefully by going through one example of each of the elements used in the script, I\u0026rsquo;ve given a basic idea of the logic and technique used to construct the dashboard. Please refer to the full code here and if you have not used Rich yet, hopefully this is a starter for you to go on and explore more! While I\u0026rsquo;ve been working on this, folks from Rich have released another mind blowing library called Textual which takes working in the terminal to a whole another level! May be soon I will give that a go and post it here, until then goodbye!\n"},{"id":3,"href":"/blog/posts/robotframework-3/","title":"Robotframework-3","section":"Posts","content":"In this blog post I\u0026rsquo;ll be going through a Test Scenario which involves multiple Test Cases with some interesting checks. I will be covering only the new things I\u0026rsquo;ve added for this Test Scenario when compared to my earlier posts, which can be found here. Test Suite begins by validating the network status on a particular device, this involves checking protocols such as OSPF, BGP, Interface Status etc. After ensuring network is in steady state, a configuration change is executed and after the change, network is validated again to ensure there has been no network impact.\nVariables # I will be using a yaml file to input the variables, this becomes convenient as we can extract data from yaml as lists, dicts etc.\n--- device: ip: \u0026#39;66.129.234.213\u0026#39; user: \u0026#39;robot\u0026#39; pwd: \u0026#39;robot123\u0026#39; port: \u0026#39;49003\u0026#39; interface: up_count: 48 ospf: nbr_full: 3 bgp: peers_up: 1 system_alarms: active_count: 2 configure: intf1: name: \u0026#39;ge-0/0/4\u0026#39; unit: 0 ipv4_addr: \u0026#39;192.168.1.1/24\u0026#39; ipv6_addr: \u0026#39;1::1/64\u0026#39; descr: \u0026#34;Testing RF\u0026#34; family: inet group: ALL save_cfg: True save_format: set First dictionary from the variables file, device, has the details needed to login to the device. As in my previous posts, I will be using Junos PyEz to interact with the device. Dictionary named configure has the parameters required for configuration change, I will go through what exactly will be configured in later sections.\nResource # By this blog post we know that the Keywords needed in our Test Suite will be defined as a Python Function in Resource file.\nfrom jnpr.junos import Device from jnpr.junos.utils.config import Config import xml.etree.ElementTree as ET def connect_to_device(host, user, pwd, port): dev = Device(host=host, user=user, password=pwd, port=port) dev.open() return dev def teardown(device): device.close() def intf_up_count(device): intf_xml = device.rpc.get_interface_information(terse=True) physical_up_count = intf_xml.xpath(\u0026#34;.//physical-interface[oper-status=\u0026#39;\\nup\\n\u0026#39;]\u0026#34;) logical_count = intf_xml.xpath(\u0026#34;.//physical-interface/logical-interface[oper-status=\u0026#39;\\nup\\n\u0026#39;]\u0026#34;) return len(physical_up_count)+len(logical_count) def ospf_nbr_count(device): ospf_xml = device.rpc.get_ospf_neighbor_information() full_nbr_count = ospf_xml.xpath(\u0026#34;.//ospf-neighbor[ospf-neighbor-state=\u0026#39;Full\u0026#39;]\u0026#34;) return len(full_nbr_count) def bgp_up_count(device): bgp_xml = device.rpc.get_bgp_summary_information() total_peers = bgp_xml.findtext(\u0026#34;.//peer-count\u0026#34;) down_peers = bgp_xml.findtext(\u0026#34;.//down-peer-count\u0026#34;) return int(total_peers)-int(down_peers) def sys_alarm_check(device): alarm_xml = device.rpc.get_system_alarm_information() alarm_count = alarm_xml.findtext(\u0026#34;.//active-alarm-count\u0026#34;) return int(alarm_count) def cfg_back(device, cfg_format): conf_xml = device.rpc.get_config(options={\u0026#39;format\u0026#39;: cfg_format}) conf_str = ET.tostring(conf_xml) conf_list = conf_str.decode(\u0026#39;UTF-8\u0026#39;).splitlines()[1:-1] hostname = device.facts[\u0026#39;hostname\u0026#39;] with open(f\u0026#34;{hostname}_backup\u0026#34;, \u0026#34;w\u0026#34;) as f: for line in conf_list: f.write(f\u0026#34;{line}\\n\u0026#34;) return hostname def configuration(device, config_vars): with Config(device, mode=\u0026#39;private\u0026#39;) as cu: cu.load(template_path=\u0026#39;config.conf\u0026#39;, template_vars=config_vars, merge=True, format=\u0026#39;set\u0026#39;) result = cu.commit() return result As you can see, there are a lot of keywords this time! As mentioned earlier, I\u0026rsquo;m using Junos PyEz here and the RPCs it offers to interact with the device. Although I\u0026rsquo;m not going go over each line of this code, as it is quite straight forward, I would still like to mention couple of them. cfg_back is a function to retrieve the current configuration in given format(json,set,xml) and back it up to a file. I\u0026rsquo;m using the RPC get_config() here, which extracts the configuration in given format but the output of RPC is still in xml. So a couple of lines of code to sanitize the output from device and store it in a file named after the hostname of the Device Under Testing (DUT). Please refer Junos PyEz documentation to know more about retrieving configuration from a device.\nconfiguration function is used to make required configuration changes on the device. Junos PyEz has an utility named Config which I will be using here to make the configuration changes. To generate the required configuration, jinja2 template is used and the required variables are taken from the Variables file. template_path is the location of the jinja2 template and template_vars is the dictionary of variables for the jinja2 template which here comes from Variables file. More information on the Junos PyEz Config utility can be found here\nset interfaces {{ name }} unit {{ unit }} description \u0026#34;{{ descr }}\u0026#34; {% if ipv4_addr %} set interfaces {{ name }} unit {{ unit }} family inet address {{ ipv4_addr }} {% endif %} {% if ipv6_addr %} set interfaces {{ name }} unit {{ unit }} family inet6 address {{ ipv6_addr }} {% endif %} set interfaces {{ name }} apply-groups {{ group }} set groups {{ group }} interfaces \u0026lt;*\u0026gt; mtu 1400 # This is from the yaml file used as Variables file (template_vars). configure: intf1: name: \u0026#39;ge-0/0/4\u0026#39; unit: 0 ipv4_addr: \u0026#39;192.168.1.1/24\u0026#39; ipv6_addr: \u0026#39;1::1/64\u0026#39; descr: \u0026#34;Testing RF\u0026#34; family: inet group: ALL save_cfg: True save_format: set Keywords # Keywords file is a collection of Keywords, having a Keywords file separately rather than defining Keywords in Test Suite itself is quite handy. Same Keywords file can be re-used in multiple Test Suites and any new Keyword would be added here to make it readily available in all the Test Suites using this Keywords file. And since this is a robot file, we can make use of various builtin keywords available in RF.\n*** Keywords *** Interface Up Count [Documentation] Keyword to check and verify number of interfaces that are UP [Arguments] ${device} ${int_up} Intf Up Count ${device} should be equal ${int_up} ${interface.up_count} Ospf Neighbor Count [Documentation] Keyword to check and verify number OSPF neighbors in Full State [Arguments] ${device} ${ospf_full} OSPF Nbr Count ${device} should be equal ${ospf_full} ${ospf.nbr_full} BGP Neighbor Count [Documentation] Keyword to check and verify the number of BGP Peers that are UP [Arguments] ${device} ${bgp_up} BGP Up Count ${device} should be equal ${bgp_up} ${bgp.peers_up} System Alarm Check [Documentation] keyword to check and verify system alarm count [Arguments] ${device} ${sys_alarms} Sys Alarm Check ${device} should be equal ${sys_alarms} ${system_alarms.active_count} Configuring Device [Documentation] keyword to make the required config changes [Arguments] ${device} ${config_vars} ${result} ${diff} Configuration ${device} ${config_vars} should be true ${result} log to console \\nConfiguration applied successfully! log to console \\n~~~~ Config Diff ~~~~\\n${diff}\\n Config Backup [Documentation] keyword to save the config before making changes, format can be set, json, xml. [Arguments] ${device} ${cfg_format} ${filename} Cfg Back ${device} ${cfg_format} log to console \\nBackup Filename: ${filename} Again, quite a few Keywords but if you look closely, they are all similar, so let\u0026rsquo;s go over a couple of them. Interface Up Count as documentation states, is used to check and verify the number of UP interfaces. This Keyword expects one argument, ${device} which will be passed from Test Suite file. ${int_up} is the variable used to hold the output from the Keyword Intf Up Count, which is nothing but a function defined in the Resource file, shown below for quick reference.\ndef intf_up_count(device): intf_xml = device.rpc.get_interface_information(terse=True) physical_up_count = intf_xml.xpath(\u0026#34;.//physical-interface[oper-status=\u0026#39;\\nup\\n\u0026#39;]\u0026#34;) logical_count = intf_xml.xpath(\u0026#34;.//physical-interface/logical-interface[oper-status=\u0026#39;\\nup\\n\u0026#39;]\u0026#34;) return len(physical_up_count)+len(logical_count) Output from the function/keyword is then passed to the builtin keyword should be equal to compare the extracted value with the expected value ${interface_count}, dictionary named interface with the key up_count in the Variables file.\nKeyword Configuration Device is worth taking a look as well, this one expects two arguments ${device} and ${config_vars}. As mentioned earlier, ${config_vars} is a dictionary with variables required by jinja2 template to generate the required configuration. This keyword returns 2 values, one if the configuration was successful or not and two the configuration difference between the running and candidate config.\nTest Suite # Everything comes together now in the Test Suite file, let\u0026rsquo;s break it down and take a look at it in sections.\n*** Settings *** Library functions.py Variables var.yml Suite Setup Test Suite Setup Resource my_keywords.robot Suite Teardown Test Suite Teardown Settings section is used to define the various files required for the Test Suite, new to this Test Suite is Suite Setup. This is used to execute anything before running the Test Cases in the Test Suite, and in this case we will be initiating the connection to the device as a part of Suite Setup. Similarly, we have Suite Teardown which is executed after all the Test Cases are executed.\n*** Keywords *** Test Suite Setup [Documentation] To initialise connection to the device ${conn} Connect To Device ${device.ip} ${device.user} ${device.pwd} ${device.port} Set Suite Variable ${conn} Test Suite Teardown [Documentation] To close the connection to the device gracefully Teardown ${conn} Test Suite Setup as mentioned earlier, is used to initialise a connection to the device, this is done using a keyword (in other words Python function) Connect To Device. ${conn} variable holds the return value from the keyword, which is nothing but the Device Object. Set Suite Variable is used to ensure the variable ${conn} is available throughout the Test Suite. Test Suite Teardown is used to close the connection to the device gracefully.\nContinuing with the Test Suite, we reach the Test Cases section. I have included 3 Test Cases, one to check the network state before change, two to make the configuration change and three to check the network state post change to validate.\n*** Test Cases *** TC - Pre checks before the configuration change \u0026amp; config backup [Documentation] In this testcase various network functions will be checked and matched against a given set ... of ideal values. Test Case would fail if there are any mismatches Sanity Checks ${conn} # Backup the current configuration before change run keyword if ${configure.save_cfg}==True ... run keyword and continue on failure Config Backup ${conn} ${configure.save_format} TC - Configuring the device [Documentation] Configure the device using \u0026#34;config.conf\u0026#34; as the Jinja2 template, with variables from var.yml ${config_vars} set variable ${configure.intf1} run keyword and continue on failure Configuring Device ${conn} ${config_vars} log to console \\nWait for 5sec before starting the Post checks sleep 5 TC - Post checks after the configuration change [Documentation] In this testcase various network functions will be checked and matched against a given set ... of ideal values. Test Case would fail if there are any mismatches Sanity Checks ${conn} Sanity Checks is a keyword which has a bunch of tests to be run as a part of network validation, shown below. run keyword if as it says, would be executed when a given condition is met. In this case, we are checking if variable ${configure.save_cfg} is set to True, this value again comes from the Variables file. When True, Config Backup keyword is executed which as seen before saves the current configuration to a .txt file.\nSanity Checks [Documentation] list of checks to run before and after a configuration change [Arguments] ${conn} log to console \\nVerifying Interface UP count run keyword and continue on failure Interface Up Count ${conn} log to console \\nVerifying OSPF Neighbor UP count run keyword and continue on failure Ospf Neighbor Count ${conn} log to console \\nVerifying BGP Peer UP count run keyword and continue on failure BGP Neighbor Count ${conn} log to console \\nVerifying System Alarms run keyword and continue on failure System Alarm Check ${conn} Going past the documentation part, we see 4 keywords in action, with the majority of them using the builtin run keyword and continue on failure option. This is a handy option when you\u0026rsquo;re running a bunch of tests and you don\u0026rsquo;t want the test execution to stop when there is a failure. With this option, we can ensure that all the tests are run and failures are captured if any.\nTest Execution # With all the required bits in place, let\u0026rsquo;s go ahead with Test Execution.\n(venv) sohanr@sohanr-mbp Robot_practise % robot configure_tc.robot ============================================================================== Configure Tc ============================================================================== TC - Pre checks before the configuration change \u0026amp; config backup ::... Verifying Interface UP count Verifying OSPF Neighbor UP count Verifying BGP Peer UP count Verifying System Alarms . Backup Filename: vMX1 TC - Pre checks before the configuration change \u0026amp; config backup ::... | PASS | ------------------------------------------------------------------------------ TC - Configuring the device :: Configure the device using \u0026#34;config.... . Configuration applied successfully! ~~~~ Config Diff ~~~~ [edit groups ALL interfaces \u0026lt;*\u0026gt;] + mtu 1400; [edit interfaces] + ge-0/0/4 { + apply-groups ALL; + unit 0 { + description \u0026#34;Testing RF\u0026#34;; + family inet { + address 192.168.1.1/24; + } + family inet6 { + address 1::1/64; + } + } + } . Wait for 5sec before starting the Post checks TC - Configuring the device :: Configure the device using \u0026#34;config.... | PASS | ------------------------------------------------------------------------------ TC - Post checks after the configuration change :: In this testcas... Verifying Interface UP count Verifying OSPF Neighbor UP count Verifying BGP Peer UP count Verifying System Alarms TC - Post checks after the configuration change :: In this testcas... | FAIL | 0 != 3 ------------------------------------------------------------------------------ Configure Tc | FAIL | 3 tests, 2 passed, 1 failed ============================================================================== Output: /Users/sohanr/PycharmProjects/Robot_practise/output.xml Log: /Users/sohanr/PycharmProjects/Robot_practise/log.html Report: /Users/sohanr/PycharmProjects/Robot_practise/report.html (venv) sohanr@sohanr-mbp Robot_practise % We see all our 3 Test Cases were executed with Test Case TC - Post checks after the configuration change failing, we will come back to this but before that, let\u0026rsquo;s appreciate the Test Case TC - Configuring the device shall we? We see the TC passed, which means the configuration on the device was successful and we also see a config difference being printed out, neat, right?\nNow coming to the failure, from the execution we see that TestCase TC - Post checks after the configuration change failed, which means some check in Sanity Checks failed. We can also see 0 != 3 is the reason for failure, but it is not clear from here what exactly failed. As I have mentioned in my earlier posts as well, the best thing about using RF for testing, in my opinion, is the logs and reports being available in html, makes it easy to view in a browser. Checking the report generated for our Test Execution, we can clearly see that out of our 3 TCs, 2 Passed and 1 Failed. Now looking at the log, we can see Test Suite Setup and Test Suite Teardown, expanding the sections, we can see what exactly happened.\nLet\u0026rsquo;s take a look at couple of sections together, rest you should be able to explore yourself as it is quite intuitive.\nI have highlighted couple of things to make it easy to look, first one is where we see the device object being returned by Junos PyEz. Second one is where we see the variable which has the device object being set as Suite Variable, documentation makes it clear!\nNow, let\u0026rsquo;s take a look at one of checks being done in TC 1, TC - Pre checks before the configuration change \u0026amp; config backup\nHere we see keyword Sanity Checks getting executed first, within which we have several keywords. Moving to Ospf Neighbor Count keyword, we can see Ospf Nbr Count being called which is defined in our Python file. This keyword or function returns the number of OSPF Neighbors in Full state, which in this is case is 3. Next, we see our verification Should Be Equal, checking if the value we defined is equal to the extracted value.\nMoving to Test Case TC - Post checks after the configuration change, where the failure occurred, let\u0026rsquo;s see if we can make sense of the failure. We can see that failure is seen in Ospf Neighbor Count keyword, we can see Ospf Nbr Count returning 0, which means there are no OSPF neighbors on the device in Full State. Due to this our verification fails as our expected value is 3 but the extracted value is 0! Checking on the device, we can see why.\nWe see all our OSPF neighbors in Exstart state! Looking closely at the configuration changes made.\nOne of our changes included changing the MTU value to 1400 for a group, ALL, which is being applied on the all the interfaces!\nThis may not have been a particularly difficult issue to troubleshoot manually but using RF we were able to test and ensure if our change was successful or not. Let\u0026rsquo;s say you want to add few more checks to your Test Suite, just write Python functions and create keywords in Keywords file, easy! Or you are performing a Software Upgrade and want to run some pre and post checks to ensure nothing is broken, you can write a Test Suite like this to automate the checks and the upgrade itself!\nI know there was a lot to go through in this post, I highly recommend having the code in front of you to help you understand better. I hope I have been clear in explaining everything, if not, please reach out to me with your feedback so that I can do a better job next time.\nReference # Junos PyEz developer guide is a great place to start if you\u0026rsquo;re new to Junos PyEz RobotFramework official user guide is extensive and gives you all the information you need to get started with RF Junos vLABs offers sandboxes with a wide variety of topologies to get a good hands-on experience on Junos. Simple Junos PyEz scripts to start with. "},{"id":4,"href":"/blog/posts/robotframework-2/","title":"Robotframework-2","section":"Posts","content":"It\u0026rsquo;s been a while since my first blog post as I mentioned there, I\u0026rsquo;m at a new job (well it\u0026rsquo;s been 2 months, so \u0026rsquo;newish\u0026rsquo;) and I\u0026rsquo;ve been busy getting to know the job(as with any job, there is a LOT to learn!).\nLearning Robot Framework (RF) has been one of my objectives in these first few months as that is entirely new for me. As I continue to learn and explore RF, I wanted to take some time out to share few things I have learnt. When it comes to network testing, it\u0026rsquo;s not always about testing features, protocols, it also involves testing the hardware components. In this blog post, I want to discuss one such test scenario. This particular Test scenario would be to restart a FPC numerous times and to check and ensure it comes back up to Online state. This is what we call a Negative Trigger Event Testing. Now imagine having to do this manually, needless to say it\u0026rsquo;s a time consuming task, this is where RF comes into play.\nIn this post, I will only explain anything new I\u0026rsquo;m using in RF as compared to my first blog post.\nvaribales.yaml # In this post, I will be using a yaml file to input the variables rather than encoding them directly in the Test Suite file. We define the variables in a yaml file, like shown below, and access them as dictionaries in the Test Suite file.\nVARS: host: 192.168.1.1 #Device under testing fpc: 3 #FPC to reboot With this variable file, we can access the host value as ${VARS.host} and similarly fpc value as ${VARS.fpc}.\nutilities.py # As mentioned in my previous post, any Keywords needed for Test execution will be defined in a Python script as functions. For this Test Case, I have defined two functions, one to check and return the state of the FPC and another one to trigger the FPC restart event, see below.\nfrom jnpr.junos import Device def fpc_restart(host,fpc): \u0026#39;\u0026#39;\u0026#39; Function to restart the FPC \u0026#39;\u0026#39;\u0026#39; dev = Device(host=host, user=\u0026#39;user\u0026#39;, password=\u0026#39;password\u0026#39;) dev.open() dev.rpc.request_chassis_fpc(slot=str(fpc),restart=True) def fpc_state(host,fpc): \u0026#39;\u0026#39;\u0026#39; Function to check the FPC status \u0026#39;\u0026#39;\u0026#39; dev = Device(host=host, user=\u0026#39;user\u0026#39;, password=\u0026#39;password\u0026#39;) dev.open() fpc_state_cli = dev.rpc.get_fpc_information().findtext(f\u0026#34;./fpc[slot=\u0026#39;{fpc}\u0026#39;]/state\u0026#34;) return fpc_state_cli I\u0026rsquo;m using Juniper\u0026rsquo;s PyEz library here as the RPC based options it provides are quite handy than CLI scraping. If you are new to PyEz, you can check out my Github repo where I\u0026rsquo;ve explained how to get started with PyEz and you can also find few basic scripts.\nTest Suite # Now let\u0026rsquo;s look at the Test Suite itself, bit by bit. First, the Settings section. Here we define the Library file, which is where we have our Keywords defined and also Variable file, which is where we have the Variables in yaml.\n*** Settings *** Library utilities.py Variables variables.yaml Next we look at the Test Case\n*** Test Cases *** TC - 1 Restart FPC [Documentation] Test Case to reboot the given FPC FOR ${i} IN RANGE 2 # i = 0, 1 Log To Console \\n~~~ Checking FPC State ~~~ ${fpc_state} = FPC State ${VARS.host} ${VARS.fpc} Run Keyword If \u0026#39;${fpc_state}\u0026#39; == \u0026#39;Online\u0026#39; Log To Console \\n~~~ FPC ${VARS.fpc} is Online\\nProceeding with restart ~~~ ... ELSE Fail \\n~~~ FPC ${VARS.fpc} is ${fpc_state},please recheck ~~~ Run Keyword If \u0026#39;${fpc_state}\u0026#39; == \u0026#39;Online\u0026#39; FPC Restart ${VARS.host} ${VARS.fpc} Sleep 300s Log To Console \\n~~~ Checking FPC State after restart ~~~ ${fpc_state} = FPC State ${VARS.host} ${VARS.fpc} Run Keyword If \u0026#39;${fpc_state}\u0026#39; == \u0026#39;Online\u0026#39; Log To Console \\n~~~ FPC is back Online! ~~~ Log To Console \\n~~~ Iteration ${i} completed ~~~ END There seems to be a LOT going on here but if you look at it closely, there actually isn\u0026rsquo;t. Going past the Documentation field, we see a FOR LOOP. To anyone familiar with programming, this is nothing new, all you need to worry about is the syntax. I always refer to the official user guide to understand the syntax and usage. In our Test Case, number of iterations are 2, which means we will be \u0026lsquo;restarting\u0026rsquo; the given FPC 2 times.\nLog To Console is a builtin Keyword RF offers, which as it says is to print something to the console. Again, I refer to the official documentation for this, here you can explore various builtin Keywords available for you to work with.\nNext, we see our first Keyword (user defined) coming into play.\n${fpc_state} = FPC State ${VARS.host} ${VARS.fpc} Run Keyword If \u0026#39;${fpc_state}\u0026#39; == \u0026#39;Online\u0026#39; Log To Console \\n~~~ FPC ${VARS.fpc} is Online\\nProceeding with restart ~~~ ... ELSE Fail \\n~~~ FPC ${VARS.fpc} is ${fpc_state},please recheck ~~~ Here we are invoking a Keyword FPC State, which is nothing but the fpc_state(host,fpc) function we defined in the utilities.py file, and passing in the variables ${VARS.host} and ${VARS.fpc}. \u0026lsquo;return\u0026rsquo; value from the function/Keyword is then stored in a variable ${fpc_state}.\nThen we see another inbuilt Keyword, Run Keyword If, which as it says, would run a Keyword if a particular condition is met. Condition in our case is if the output returned from the FPC State function is Online or not. If our condition is met (or in other words \u0026lsquo;True\u0026rsquo;) then we execute a Keyword Log To Console, which as explained before would log a message that the FPC we are checking is Online and that we are proceeding with restarting it. But if our condition FAILs, we have a ELSE clause to take care of that. If the ELSE clause is hit, we will first and foremast FAIL our Test Case, that is why we have used another builtin Keyword FAIL and we can also print a message to Console as to why we are failing the Test Case, neat isn\u0026rsquo;t it? Note, if you are wondering what the ... signifies, it is used when you want to continue the code on next line, so as to not over extend the same line.\nContinuing further, we are now invoking our next function/Keyword but only when our condition is met! Condition is still the same one we looked at above!\nRun Keyword If \u0026#39;${fpc_state}\u0026#39; == \u0026#39;Online\u0026#39; FPC Restart ${VARS.host} ${VARS.fpc} Sleep 300s Same 2 variables are passed to FPC Restart Keyword as well. Sleep as you would have guessed it, is a builtin Keyword to, there is no better way to put it, sleep.\nNext section is failry simple as we now check the FPC State again (after 300s remember) to ensure it has come back Online.\nLog To Console \\n~~~ Checking FPC State after restart ~~~ ${fpc_state} = FPC State ${VARS.host} ${VARS.fpc} Run Keyword If \u0026#39;${fpc_state}\u0026#39; == \u0026#39;Online\u0026#39; Log To Console \\n~~~ FPC is back Online! ~~~ Log To Console \\n~~~ Iteration ${i} completed ~~~ The whole process will be repeated as a part of our FOR LOOP, in this case, twice.\nExecution # (personal_env) sohanr@sohanr-mbp:~/envs$ robot fpc_reboot.robot ============================================================================== Fpc Reboot ============================================================================== TC - 1 Restart FPC :: Test Case to reboot the given FPC ~~~ Checking FPC State ~~~ ~~~ FPC 3 is Online Proceeding with restart ~~~ ~~~ Checking FPC State after restart ~~~ ~~~ FPC is back Online! ~~~ ~~~ Iteration 0 completed ~~~ ~~~ Checking FPC State ~~~ ~~~ FPC 3 is Online Proceeding with restart ~~~ ~~~ Checking FPC State after restart ~~~ ~~~ FPC is back Online! ~~~ ~~~ Iteration 1 completed ~~~ TC - 1 Restart FPC :: Test Case to reboot the given FPC | PASS | ------------------------------------------------------------------------------ Fpc Reboot | PASS | 1 test, 1 passed, 0 failed ============================================================================== Output: /homes/sohanr/envs/output.xml Log: /homes/sohanr/envs/log.html Report: /homes/sohanr/envs/report.html (personal_env) sohanr@sohanr-mbp:~/envs$ I\u0026rsquo;m hoping the output is self explaintory, as always with RF, we get the Log and Report in html format which makes viewing it really easy.\nAlso to just show a FAIL scenario, I will provide a FPC slot which is not in use and let\u0026rsquo;s see the output for it.\n(personal_env) sohanr@sohanr-mbp:~/envs$ robot fpc_reboot.robot ============================================================================== Fpc Reboot ============================================================================== TC - 1 Restart FPC :: Test Case to reboot the given FPC ~~~ Checking FPC State ~~~ TC - 1 Restart FPC :: Test Case to reboot the given FPC | FAIL | ~~~ FPC 2 is Empty,please recheck ~~~ ------------------------------------------------------------------------------ Fpc Reboot | FAIL | 1 test, 0 passed, 1 failed ============================================================================== Output: /homes/sohanr/envs/output.xml Log: /homes/sohanr/envs/log.html Report: /homes/sohanr/envs/report.html (personal_env) sohanr@sohanr-mbp:~/envs$ Conclusion # As you might have seen with this post and the previous one, working with Robot Framework is fairly easy as the Keywords are in plain English and they do exactly what they say! I hope this blog post has been informative, as always please feel to reach out to me with any feedback/comments.\n"},{"id":5,"href":"/blog/posts/robotframework-1/","title":"Robotframework-1","section":"Posts","content":"In my new job role as a Test Engineer, knowing how to use Robot Framework for Automating Test Cases is crucial, to save time and to make testing more fun! As I\u0026rsquo;m going through this learning journey, I wanted to blog about it for anyone who is looking to start this journey and also to help me understand things in a better way.\nThere are plenty of good resources out there which explains the Robot Framework and it\u0026rsquo;s components. Best place to start would be the Robot Framework Documentation, which shows some interactive examples and very clear explaination. During my learning what I have come to realise is, there are lot of resources around Robot Framework used for Application Testing but there are not a lot of resources focused on Network Testing(or maybe I haven\u0026rsquo;t been thorough with my search!). That\u0026rsquo;s also one of the reaons for starting this blog, to give a Network Engineer\u0026rsquo;s perspective on Robot Framework and use the examples around networking to help us understand this better.\nSoftware Version Check # For my first example, I wanted to create a Test Case to get the Junos Software Version from a device and compare it with an expected SW version.\nFirst component of our task would be to construct a Python code to get the SW version from a device. I\u0026rsquo;m using Juniper\u0026rsquo;s PyEz Library to get this done. As you can see, it is a very simple script to gather facts and then from the output dictionary filtering out just the value of version using the key named version. If you have gone through the Robot Framework documentation, you would know that it is a Keyword driven framework. And in our case, we define the Keyword using a Python function. That\u0026rsquo;s why you are seeing a function check_version defined in the script which returns the Software Version.\nfrom jnpr.junos import Device def check_version(host): dev = Device(host=host, user=\u0026#39;robot\u0026#39;, password=\u0026#39;Junos12345\u0026#39;) dev.open() return dev.facts[\u0026#39;version\u0026#39;] Second component would be constructing the Robot File (also called Test Suite) with our Test Case. *** Settings *** Library pyez_version.py *** Variables *** ${host} = 10.10.10.11 ${expected_version} = 17.1R1.8 *** Test Cases *** TestCase1 [Documentation] Checking if the SW version matches the requirement ${version_output} = Check Version ${host} Should be equal ${version_output} ${expected_version} SW version doesn\u0026#39;t match the requirement Let\u0026rsquo;s look at some of the components of our Test Suite.\nIn the Settings section, we import the Library, which in our case is the Python script with the function defined to fetch the SW version.\n*** Settings *** Library pyez_version.py Next, we have the Variables section, which as it says is where you\u0026rsquo;d define the Variables. There are multiple ways of defining Variables, we can do it as I have shown below or pass in a list, dictionary etc. host Variable here has the IP address of the device we need to connect, which would be sent as an input to the Python script. expected_version is the Variable used to enter the SW version we wish to test/match on the device.\n*** Variables *** ${host} = 10.10.10.11 ${expected_version} = 17.1R1.8 Now the Test Cases section. Documentation Keyword let\u0026rsquo;s us provide a description for our Test Case.\nThen we see a version_output Variable, which stores the output returned by the Keyword Check Version. This Keyword is nothing but the function we defined in our Python script, just replace underscore with a space and if you look closely, it is case insensitive. After the Keyword, followed by a cell seperator(4 spaces), we provide the input Varibale for our function, which in this case is the IP address of the Host.\nNext we see what is called a built-in Keyword, these come as a part of Robot Framework and doesn\u0026rsquo;t require any Library imports. Built-in Keyword here Should be equal compares two values and the Test Case is determined as PASS if they match and FAIL if they don\u0026rsquo;t. We mention the two values to be compared seperated by a cell seperator. And to customize a message in case of FAIL, we can define a message SW version doesn\u0026rsquo;t match the requirement, which would be displayed when the Test Case FAILs.\n*** Test Cases *** TestCase1 [Documentation] Checking if the SW version matches the requirement ${version_output} = Check Version ${host} Should be equal ${version_output} ${expected_version} SW version doesn\u0026#39;t match the requirement With our required components in place, let\u0026rsquo;s execute the Test Case and see the results.\nPS C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\u0026gt; robot pyez_version.robot ============================================================================== Pyez Version ============================================================================== TestCase1 :: Checking if the SW version matches the requirement | PASS | ------------------------------------------------------------------------------ Pyez Version | PASS | 1 test, 1 passed, 0 failed ============================================================================== Output: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\output.xml Log: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\log.html Report: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\report.html PS C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\u0026gt; Our Test Case Passed! Now, let\u0026rsquo;s change the expected SW Version and see if Robot can detect it and fail our Test Case.\nPS C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\u0026gt;robot pyez_version.robot ============================================================================== Pyez Version ============================================================================== TestCase1 :: Checking if the SW version matches the requirement | FAIL | SW version doesn\u0026#39;t match the requirement: 17.1R1.8 != 16.1R1.8 ------------------------------------------------------------------------------ Pyez Version | FAIL | 1 test, 0 passed, 1 failed ============================================================================== Output: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\output.xml Log: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\log.html Report: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\report.html PS C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\u0026gt; Now our Test Case Failed! And we can clearly see that the expected SW version we passed, 16.1R1.8, did not match the extracted SW version, 17.1R1.8!\nRobot also let\u0026rsquo;s us pass the Variable from the command line, i.e. instead of hardcoding the expected_version varibale in the Test Suite, we can input this from the command line. Let\u0026rsquo;s see how to do it, updated Test Suite looks like below, only change is that I have commeneted the expected_variable under the Variables section.\n*** Settings *** Library pyez_version.py *** Variables *** ${host} = 10.10.10.11 #${expected_version} = 16.1R1.8 *** Test Cases *** TestCase1 [Documentation] Checking if the SW version matches the requirement ${version_output} = Check Version ${host} Should be equal ${version_output} ${expected_version} SW version doesn\u0026#39;t match the requirement To enter the Variable from command line, we use -v key, as shown below.\nPS C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\u0026gt;robot -v expected_version:16.1R1.8 pyez_version.robot ============================================================================== Pyez Version ============================================================================== TestCase1 :: Checking if the SW version matches the requirement | FAIL | SW version doesn\u0026#39;t match the requirement: 17.1R1.8 != 16.1R1.8 ------------------------------------------------------------------------------ Pyez Version | FAIL | 1 test, 0 passed, 1 failed ============================================================================== Output: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\output.xml Log: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\log.html Report: C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\\report.html PS C:\\Users\\User\\PycharmProjects\\Robotframework\\Junos\u0026gt; Another great feature Robot Framework offers is, Test reports and logs are generated in html which makes reading it very easy using a web browser. Path to the Log and Report is printed out to the Console as you can see in the above output.\nReport for our Test Suite is shown below We can toggle to the Log file by clicking on LOG displayed on the top right corner, LOG file our Test Case is shown below And with that we have completed our first Testing using Robot Framework! Hopefully, you and I can now explore more and start Testing complex network related things.\nAs this is my first take at blogging, I\u0026rsquo;d really appreciate your feedback so that I can keep getting better at this!\nDependencies # You need to have Robot Framework installed and any other dependencies based on your Python script. In this example, that would be PyEz.\npython -m pip install robotframework junos-eznc "}]